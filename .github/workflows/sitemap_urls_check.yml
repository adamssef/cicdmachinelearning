name: Sitemap URL Checker
on:
  workflow_dispatch:
    inputs:
      sitemap_urls:
        description: 'Sitemap URLs (one per line)'
        required: true
        type: string
      check_alternates:
        description: 'Check alternate language URLs'
        required: false
        type: boolean
        default: true

jobs:
  check-urls:
    runs-on: ubuntu-latest
    steps:
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests xmltodict
          
      - name: Check URLs
        env:
          SITEMAP_URLS: ${{ inputs.sitemap_urls }}
          CHECK_ALTERNATES: ${{ inputs.check_alternates }}
        run: |
          import requests
          import xmltodict
          import sys
          import os
          
          def check_url(url):
              try:
                  response = requests.get(url, allow_redirects=False)
                  if response.status_code not in [200, 301]:
                      print(f"❌ Error: {url} returned status code {response.status_code}")
                      return False
                  print(f"✅ Success: {url} returned status code {response.status_code}")
                  return True
              except Exception as e:
                  print(f"❌ Error: {url} raised an exception: {str(e)}")
                  return False
          
          def process_sitemap(sitemap_url):
              try:
                  print(f"\nProcessing sitemap: {sitemap_url}")
                  response = requests.get(sitemap_url)
                  response.raise_for_status()
                  sitemap = xmltodict.parse(response.text)
                  
                  urls = set()  # Using set to avoid duplicates
                  check_alternates = os.environ['CHECK_ALTERNATES'].lower() == 'true'
                  
                  # Process each URL entry
                  urlset = sitemap['urlset']['url']
                  if not isinstance(urlset, list):
                      urlset = [urlset]
                      
                  for url_entry in urlset:
                      # Add main URL
                      urls.add(url_entry['loc'])
                      
                      # Add alternate language URLs if enabled
                      if check_alternates and 'xhtml:link' in url_entry:
                          links = url_entry['xhtml:link']
                          if not isinstance(links, list):
                              links = [links]
                          
                          for link in links:
                              if link.get('@rel') == 'alternate':
                                  urls.add(link.get('@href'))
                  
                  print(f"Found {len(urls)} unique URLs in {sitemap_url}")
                  return list(urls)
                  
              except Exception as e:
                  print(f"Failed to fetch or parse sitemap from {sitemap_url}: {str(e)}")
                  return []
          
          # Get sitemap URLs from workflow input
          sitemap_urls = [url.strip() for url in os.environ['SITEMAP_URLS'].split('\n') if url.strip()]
          
          # Process all sitemaps
          all_urls = []
          for sitemap_url in sitemap_urls:
              urls = process_sitemap(sitemap_url)
              all_urls.extend(urls)
          
          if not all_urls:
              print("No URLs found in any sitemap!")
              sys.exit(1)
              
          print(f"\nTotal unique URLs found across all sitemaps: {len(all_urls)}")
          
          # Check all URLs
          failed = False
          for url in all_urls:
              if not check_url(url):
                  failed = True
          
          if failed:
              print("\nSome URLs failed the check. See logs above for details.")
              sys.exit(1)
          
          print("\nAll URLs passed the check!")
        shell: python
